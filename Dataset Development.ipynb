{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage import feature\n",
    "from skimage import data, exposure\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for LBP\n",
    "radius = 3\n",
    "n_points = 8 * radius\n",
    "\n",
    "# local_binary_pattern(x, n_points, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOG \n",
    "\n",
    "hog_vec, hog_vis = feature.hog((cv2.imread(filepath,0))\n",
    "                               ,visualize=True, pixels_per_cell=(2,2)\n",
    "                               , cells_per_block=(2,2),block_norm='L2')\n",
    "\n",
    "\n",
    "plt.imshow(hog_vis)\n",
    "print(hog_vec)\n",
    "print(hog_vis.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm func.\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "def nor(x):\n",
    "    \n",
    "    return min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  combine all 3 filter\n",
    "\n",
    "k=np.stack([nor(data['X'][0]),nor(data['LBP'][0]),nor(data['HOG_vis'][0])],axis=2)\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/raghav/Downloads/CK+48'\n",
    "category=['fear', 'anger', 'surprise', 'happy', 'sadness', 'disgust', 'contempt']\n",
    "\n",
    "# os.listdir('/home/raghav/Downloads/CK+48/fear')\n",
    "# arr=cv2.imread\n",
    "# arr\n",
    "cv2.imread(path +'/'+category[0]+'/'+os.listdir(os.path.join(path,category[0]))[0]).shape\n",
    "\n",
    "# plt.imread()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CK+ dataset building\n",
    "x,y,lbp,hog_visual,hog_vector=[],[],[],[],[]\n",
    "X1=[]\n",
    "for i,label  in enumerate (category):\n",
    "    for img in tqdm(os.listdir(os.path.join(path,label))):\n",
    "        filepath= path + '/' + label + '/' + img\n",
    "        arr = cv2.imread(filepath,0)\n",
    "        LBP = local_binary_pattern(arr, n_points, radius)\n",
    "        hog_vec, hog_vis = feature.hog(arr\n",
    "                               ,visualize=True, pixels_per_cell=(2,2)\n",
    "                               , cells_per_block=(2,2),block_norm='L2')\n",
    "        x.append(arr)\n",
    "        y.append(label)\n",
    "        lbp.append(LBP)\n",
    "        hog_visual.append(hog_vis)\n",
    "        hog_vector.append(hog_vec)\n",
    "#         X1.append(np.stack([nor(arr),nor(LBP),nor(hog_vis)],axis=2))\n",
    "        \n",
    "        \n",
    "dat={'X':x,'LBP':lbp,'HOG_vis':hog_visual,'HOG_vec':hog_vector,'Y':y}\n",
    "del x,lbp,hog_visual,hog_vector,y\n",
    "data1=pd.DataFrame(dat)\n",
    "del dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_pickle('/home/raghav/Downloads/data1.pkl')\n",
    "del data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FER13 Data set\n",
    "\n",
    "path='/home/raghav/Downloads/fer2013.csv'\n",
    "emotion_label_to_text = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}\n",
    "\n",
    "data=pd.read_csv(path)\n",
    "p=len(data)//4\n",
    "dat=[data.iloc[p:2*p],data.iloc[2*p:3*p],data.iloc[3*p:],]\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8971/8971 [25:12<00:00,  5.93it/s]\n",
      "  0%|          | 0/8971 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 2 made!  :  /home/raghav/Downloads/data2_2.pkl\n",
      "Memory Flushed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8971/8971 [26:30<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 3 made!  :  /home/raghav/Downloads/data2_3.pkl\n",
      "Memory Flushed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 7176/8974 [20:54<05:45,  5.21it/s]"
     ]
    }
   ],
   "source": [
    "def make_fer13(dat):\n",
    "    \n",
    "    itr=1\n",
    "    for info in dat:\n",
    "        x,y,lbp,hog_visual,hog_vector=[],[],[],[],[]\n",
    "        X=[]\n",
    "        \n",
    "        y=(info.emotion)\n",
    "        y=0\n",
    "        itr=itr+1\n",
    "        s='_'+str(itr)\n",
    "        idx=0\n",
    "        for i in tqdm(info.index):\n",
    "            \n",
    "            x.append( np.array(info.pixels[i].split(' ')).reshape(48, 48).astype('float32'))\n",
    "            lbp.append(local_binary_pattern(x[idx], n_points, radius))\n",
    "            hog_vec, hog_vis = feature.hog(x[idx],visualize=True, pixels_per_cell=(2,2), cells_per_block=(2,2),block_norm='L2')\n",
    "            idx=idx+1\n",
    "            hog_visual.append(hog_vis)\n",
    "            hog_vector.append(hog_vec)\n",
    "            \n",
    "        \n",
    "#         X.append(np.stack([nor(x[i]),nor(lbp[i]),nor(hog_visual[i])],axis=2))\n",
    "        \n",
    "        \n",
    "        \n",
    "        dat={'X':x,'LBP':lbp,'HOG_vis':hog_visual,'HOG_vec':hog_vector,'Y':y}\n",
    "        #     print(dat['Y'].dtype)\n",
    "        del x,lbp,hog_visual,hog_vector,y\n",
    "        data2=pd.DataFrame(dat)\n",
    "        del dat \n",
    "        data2.to_pickle('/home/raghav/Downloads/data2'+s+'.pkl')\n",
    "        print(\"Checkpoint\",itr,\"made!  :  \"+'/home/raghav/Downloads/data2'+s+'.pkl')\n",
    "        print(\"Memory Flushed!\")\n",
    "        del data2\n",
    "      \n",
    "    \n",
    "    return\n",
    "\n",
    "make_fer13(dat)\n",
    "    \n",
    "# i = np.stack(i, axis=0)\n",
    "# e = np.stack(enc,axis=0)\n",
    "# imgs=np.hstack((i,e))\n",
    "# img_array=imgs.reshape((21264,48,48,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:  1\n",
      "Openinig File ( 1 )\n",
      "Opened!\n",
      "Openinig File ( 2 )\n"
     ]
    }
   ],
   "source": [
    "path='/home/raghav/Downloads/data2_'\n",
    "df=pd.read_pickle('/home/raghav/Downloads/data1.pkl')\n",
    "for i in [1,3]:\n",
    "    print(\"Pass: \",i)\n",
    "#     if i+1 ==5:\n",
    "#         break\n",
    "    file=path + str(i) + '.pkl'\n",
    "    print(\"Openinig File (\",i,\")\")\n",
    "    df_temp1=pd.read_pickle(file)\n",
    "    print(\"Opened!\")\n",
    "    file=path + str(i+1) + '.pkl'\n",
    "    print(\"Openinig File (\",i+1,\")\")\n",
    "    df_temp2=pd.read_pickle(file)\n",
    "    print(\"Opened!\")\n",
    "    print(\"Combining!\")\n",
    "    df_temp1=pd.concat([df_temp1,df_temp2],ignore_index=True)\n",
    "    print(\"Done!\")\n",
    "    del df_temp2\n",
    "    df_temp1.to_pickle('/home/raghav/Downloads/df_'+str(i)+'.pkl')\n",
    "    print(\"Checkpoint\",i,\"made!\")\n",
    "    print(\"Memory Flushed!\")\n",
    "    del df_temp1\n",
    "    \n",
    "\n",
    "\n",
    "# df1=pd.read_pickle('/home/raghav/Downloads/data2_1.pkl')\n",
    "# df1.head()\n",
    "# df2=pd.read_pickle('/home/raghav/Downloads/data2_2.pkl')\n",
    "# df2.head()\n",
    "# df3=pd.read_pickle('/home/raghav/Downloads/data2_3.pkl')\n",
    "# df3.head()\n",
    "# df4=pd.read_pickle('/home/raghav/Downloads/data2_4.pkl')\n",
    "# df=pd.read_pickle('/home/raghav/Downloads/data1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "# del df_temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp1=pd.concat([df_temp1,df_temp2],ignore_index=True)\n",
    "# print(\"Done!\")\n",
    "# del df_temp2\n",
    "# df_temp1.to_pickle('/home/raghav/Downloads/df_'+str(i)+'.pkl')\n",
    "# print(\"Checkpoint\",i,\"made!\")\n",
    "# print(\"Memory Flushed!\")\n",
    "# del df_temp1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
